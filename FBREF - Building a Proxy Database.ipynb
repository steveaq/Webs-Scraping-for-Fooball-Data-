{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our own data Pipe lines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import warnings\n",
    "import numpy as np\n",
    "from math import pi\n",
    "import os\n",
    "from math import pi\n",
    "from urllib.request import urlopen\n",
    "import matplotlib.patheffects as pe\n",
    "from highlight_text import fig_text\n",
    "from adjustText import adjust_text\n",
    "\n",
    "import unicodedata\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_merge(df_1, df_2, key1, key2, threshold=97, limit=1):\n",
    "    \"\"\"\n",
    "    :param df_1: the left table to join\n",
    "    :param df_2: the right table to join\n",
    "    :param key1: key column of the left table\n",
    "    :param key2: key column of the right table\n",
    "    :param threshold: how close the matches should be to return a match, based on Levenshtein distance\n",
    "    :param limit: the amount of matches that will get returned, these are sorted high to low\n",
    "    :return: dataframe with boths keys and matches\n",
    "    \"\"\"\n",
    "    s = df_2[key2].tolist()\n",
    "    \n",
    "    m = df_1[key1].apply(lambda x: process.extract(x, s, limit=limit))    \n",
    "    df_1['matches'] = m\n",
    "    \n",
    "    m2 = df_1['matches'].apply(lambda x: ', '.join([i[0] for i in x if i[1] >= threshold]))\n",
    "    df_1['matches'] = m2\n",
    "    \n",
    "    return df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accents(input_str):\n",
    "    nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
    "    only_ascii = nfkd_form.encode('ASCII', 'ignore')\n",
    "    only_ascii = str(only_ascii)\n",
    "    only_ascii = only_ascii[2:-1]\n",
    "    only_ascii = only_ascii.replace('-', ' ')\n",
    "    return only_ascii\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_urls(x):  \n",
    "    url = x\n",
    "    data  = requests.get(url).text\n",
    "    soup = BeautifulSoup(data)\n",
    "    player_urls = []\n",
    "    links = BeautifulSoup(data).select('th a')\n",
    "    urls = [link['href'] for link in links]\n",
    "    urls = list(set(urls))\n",
    "    full_urls = []\n",
    "    for y in urls:\n",
    "        full_url = \"https://fbref.com\"+y\n",
    "        full_urls.append(full_url)\n",
    "    team_names = []\n",
    "    for team in urls: \n",
    "        team_name_slice = team[20:-6]\n",
    "        team_names.append(team_name_slice)\n",
    "    list_of_tuples = list(zip(team_names, full_urls))\n",
    "    Team_url_database = pd.DataFrame(list_of_tuples, columns = ['team_names', 'urls'])\n",
    "    return Team_url_database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_urls = get_team_urls(\"https://fbref.com/en/comps/9/Premier-League-Stats\")  \n",
    "full_urls = list(team_urls.urls.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_url_database(full_urls):    \n",
    "    appended_data = []\n",
    "    for team_url in full_urls:\n",
    "        url = team_url\n",
    "        # print(url)\n",
    "        player_db = pd.DataFrame()\n",
    "        player_urls = []\n",
    "        data  = requests.get(url).text\n",
    "        links = BeautifulSoup(data).select('th a')\n",
    "        urls = [link['href'] for link in links]\n",
    "        player_urls.append(urls)\n",
    "        player_urls  = [item for sublist in player_urls  for item in sublist]\n",
    "        player_urls.sort()\n",
    "        player_urls = list(set(player_urls))\n",
    "        p_url = list(filter(lambda k: 'players' in k, player_urls))\n",
    "        url_final = []\n",
    "        for y in p_url:\n",
    "            full_url = \"https://fbref.com\"+y\n",
    "            url_final.append(full_url)\n",
    "        player_names = []\n",
    "        for player in p_url: \n",
    "            player_name_slice = player[21:]\n",
    "            player_name_slice = player_name_slice.replace('-', ' ')\n",
    "            player_names.append(player_name_slice)\n",
    "        # player_names\n",
    "        list_of_tuples = list(zip(player_names, url_final))\n",
    "        play_url_database = pd.DataFrame(list_of_tuples, columns = ['Player', 'urls'])\n",
    "        player_db = pd.concat([play_url_database])\n",
    "\n",
    "        html = requests.get(url).text\n",
    "        data2 = BeautifulSoup(html, 'html5')\n",
    "        table = data2.find('table')\n",
    "        cols = []\n",
    "\n",
    "        for header in table.find_all('th'):\n",
    "            cols.append(header.string)\n",
    "\n",
    "        columns = cols[8:37] #gets necessary column headers\n",
    "        players = cols[37:-2]\n",
    "\n",
    "        #display(columns)\n",
    "        rows = [] #initliaze list to store all rows of data\n",
    "        for rownum, row in enumerate(table.find_all('tr')): #find all rows in table\n",
    "            if len(row.find_all('td')) > 0: \n",
    "                rowdata = [] #initiliaze list of row data\n",
    "                for i in range(0,len(row.find_all('td'))): #get all column values for row\n",
    "                    rowdata.append(row.find_all('td')[i].text)\n",
    "                rows.append(rowdata)\n",
    "        df = pd.DataFrame(rows, columns=columns)\n",
    "\n",
    "        df.drop(df.tail(2).index,inplace=True)\n",
    "        df[\"Player\"] = players\n",
    "        df = df[[\"Player\",\"Pos\",\"Age\", \"Starts\"]]\n",
    "\n",
    "        df['Player'] = df.apply(lambda x: remove_accents(x['Player']), axis=1)\n",
    "        test_merge = fuzzy_merge(df, player_db, 'Player', 'Player', threshold=90)\n",
    "        test_merge = test_merge.rename(columns={'matches': 'Player', 'Player': 'matches'})\n",
    "        # test_merge = test_merge.drop(columns=['matches'])\n",
    "        final_merge = test_merge.merge(player_db, on='Player', how='left')\n",
    "        # list_of_dfs.append(final_merge)\n",
    "        appended_data.append(final_merge)\n",
    "    appended_data = pd.concat(appended_data)\n",
    "    return appended_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPL_Player_db = general_url_database(full_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def years_converter(variable_value):\n",
    "    years = variable_value[:-4]\n",
    "    days = variable_value[3:]\n",
    "    years_value = pd.to_numeric(years)\n",
    "    days_value = pd.to_numeric(days)\n",
    "    day_conv = days_value/365\n",
    "    final_val = years_value + day_conv\n",
    "\n",
    "    return final_val\n",
    "\n",
    "EPL_Player_db['Age'] = EPL_Player_db.apply(lambda x: years_converter(x['Age']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DF', 'MF', 'FW', 'GK', 'FW,MF', 'MF,DF', 'MF,FW', 'DF,FW',\n",
       "       'DF,MF', 'FW,DF'], dtype=object)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPL_Player_db.Pos.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
