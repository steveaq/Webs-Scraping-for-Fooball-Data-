{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from mobfot import MobFot\n",
    "from mplsoccer import Pitch\n",
    "\n",
    "from PIL import Image\n",
    "import urllib\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "# import klib as kb\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.patheffects as path_effects\n",
    "import matplotlib.font_manager as fm\n",
    "# import wes\n",
    "import matplotlib as mpl\n",
    "import warnings\n",
    "import numpy as np\n",
    "from math import pi\n",
    "from urllib.request import urlopen\n",
    "from matplotlib.transforms import Affine2D\n",
    "import mpl_toolkits.axisartist.floating_axes as floating_axes\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font_path = \"../assets/fonts\"\n",
    "for x in os.listdir(font_path):\n",
    "    for y in os.listdir(f\"{font_path}/{x}\"):\n",
    "        if y.split(\".\")[-1] == \"ttf\":\n",
    "            fm.fontManager.addfont(f\"{font_path}/{x}/{y}\")\n",
    "            try:\n",
    "                fm.FontProperties(weight=y.split(\"-\")[-1].split(\".\")[0].lower(), fname=y.split(\"-\")[0])\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "plt.style.use(\"../assets/stylesheets/soc_base.mplstyle\")\n",
    "plt.rcParams['font.family'] = 'Karla'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_table = pd.read_csv(\"CSVs/EPL_Teams_URLs.csv\")\n",
    "team_table = team_table[[\"team_names\",\"urls\"]]\n",
    "\n",
    "def get_wages(url):    \n",
    "    start = url[0:37]+ \"2023-2024/wages/\"\n",
    "    def remove_first_n_char(org_str, n):\n",
    "        mod_string = \"\"\n",
    "        for i in range(n, len(org_str)):\n",
    "            mod_string = mod_string + org_str[i]\n",
    "        return mod_string\n",
    "    mod_string = remove_first_n_char(url, 37)\n",
    "    final_string = start+mod_string+\"-Wage-Details\"   \n",
    "    return final_string\n",
    "\n",
    "team_table['wages'] = team_table.apply(lambda x: get_wages(x['urls']), axis=1)\n",
    "\n",
    "team_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def league_wages_df(match_links):\n",
    "    data_append = []\n",
    "    for x in match_links:\n",
    "        print(x)\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        url = x\n",
    "        page =requests.get(url)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        name = [element.text for element in soup.find_all(\"span\")]\n",
    "        name = name[7]\n",
    "        # name = name[10:]\n",
    "\n",
    "        # Remove last 17 characters\n",
    "        name = name[:-17]\n",
    "        html_content = requests.get(url).text.replace('<!--', '').replace('-->', '')\n",
    "        df = pd.read_html(html_content)\n",
    "        wage_stats = df[0]\n",
    "        def remove_nan_rows(df, column_name):\n",
    "            df.dropna(subset=[column_name], inplace=True)\n",
    "            return df\n",
    "        wage_stats = remove_nan_rows(wage_stats, \"Weekly Wages\")\n",
    "        def extract_currency_values(column_value):\n",
    "            parts = column_value.split(\" \")\n",
    "            pound_value = parts[0] + \"  \" + parts[1]\n",
    "            euro_value = parts[3]\n",
    "            dollar_value = parts[4]\n",
    "            return pound_value, euro_value, dollar_value\n",
    "\n",
    "        wage_stats[[\"Pound Value\", \"Euro Value\", \"Dollar Value\"]] = wage_stats[\"Weekly Wages\"].apply(extract_currency_values).apply(pd.Series)\n",
    "        def convert_pound_values_to_int(df, column_name):\n",
    "            df['new_pound_value'] = df[column_name].str.replace('Â£', '').str.replace(',', '').astype(int)\n",
    "            return df\n",
    "        wage_stats = convert_pound_values_to_int(wage_stats, \"Pound Value\")\n",
    "        wage_stats = wage_stats[[\"Player\", \"Nation\",\"Pos\",\"Age\",\"new_pound_value\"]]\n",
    "        # wage_stats['Player'] = name\n",
    "        data_append.append(wage_stats)\n",
    "        del df, soup\n",
    "        time.sleep(10)\n",
    "    df_total = pd.concat(data_append)\n",
    "\n",
    "    return df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_links = list(team_table.wages.unique())\n",
    "wages_df = league_wages_df(match_links)\n",
    "wages_df.to_csv(\"CSVs/EPL_Player_Wages.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "team_ids = pd.read_csv(\"CSVs/fotmob_epl_team_ids.csv\")\n",
    "client = MobFot()\n",
    "\n",
    "def get_epl_ratings(team_ids):\n",
    "    dataframes = []\n",
    "    for t_id in team_ids.team_id.unique():\n",
    "        dict1 = client.get_team(t_id)\n",
    "\n",
    "        def extract_names_and_urls(data):\n",
    "            names = []\n",
    "            urls = []\n",
    "            for athlete in data['details']['sportsTeamJSONLD']['athlete']:\n",
    "                names.append(athlete['name'])\n",
    "                urls.append(athlete['url'])\n",
    "            df = pd.DataFrame({'Name': names, 'URL': urls})\n",
    "            return df\n",
    "\n",
    "        player_rating = extract_names_and_urls(dict1)\n",
    "\n",
    "        fm_ratings = []\n",
    "        player_ids = (player_rating.URL.unique())\n",
    "        def extract_rating(player_ids):\n",
    "            for id in player_ids:\n",
    "                print(id)\n",
    "                numbers = re.findall(r'\\d+', id)\n",
    "                id = ''.join(numbers)\n",
    "                dict2 = client.get_player(id)\n",
    "                l1= dict2['careerStatistics']\n",
    "                def get_fotmob_rating(data, seasonid):\n",
    "                    if data == None:\n",
    "                        fm_ratings.append(None)\n",
    "                    else:\n",
    "                        for league in data:\n",
    "                            for season in league['seasons']:\n",
    "                                if season['seasonId'] == seasonid:\n",
    "                                    for stat in season['stats'][0]['statsArr']:\n",
    "                                        if stat[0] == 'FotMob rating':\n",
    "                                            return stat[1]['value']['num']\n",
    "                    return None\n",
    "                rating = get_fotmob_rating(l1, 879290)  \n",
    "                fm_ratings.append(rating)  # Append None if rating is not found\n",
    "\n",
    "            return(fm_ratings)\n",
    "\n",
    "        table = extract_names_and_urls(dict1)\n",
    "        fm_ratings = extract_rating(player_ids)\n",
    "        fm_ratings = fm_ratings[:len(table)]\n",
    "\n",
    "        # Create a DataFrame with the player_ids and fm_ratings\n",
    "        df2 = pd.DataFrame({'URL': player_ids, 'ratings': fm_ratings})\n",
    "\n",
    "        # Merge the DataFrame with the original data using player_id as the key\n",
    "        new_table = table.merge(df2, on='URL', how='left')\n",
    "\n",
    "        new_table['team_id'] = t_id\n",
    "        dataframes.append(new_table)\n",
    "    final = pd.concat(dataframes)\n",
    "\n",
    "    return final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epl_player_ratings = get_epl_ratings(team_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wages_df = pd.read_csv(\"CSVs/EPL_Player_Wages.csv\")\n",
    "wages_df.rename(columns={'Player': 'Name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "def get_approximate_match(query, choices):\n",
    "    return process.extractOne(query, choices)[0]\n",
    "\n",
    "# Create a dictionary to store approximate matches\n",
    "name_mapping = {}\n",
    "\n",
    "# Loop through each name in wages dataframe\n",
    "for name in wages_df['Name']:\n",
    "    # Find approximate match in epl_player_ratings dataframe\n",
    "    match = get_approximate_match(name, epl_player_ratings['Name'])\n",
    "    # Store the approximate match in the dictionary\n",
    "    name_mapping[name] = match\n",
    "\n",
    "# Replace the 'Name' column in wages dataframe with the approximate match\n",
    "wages_df['Name'] = wages_df['Name'].map(name_mapping)\n",
    "\n",
    "# Perform left join on 'Name' column\n",
    "merged_df = pd.merge(wages_df, epl_player_ratings, on='Name', how='left')\n",
    "\n",
    "# merged_df.drop('Unnamed: 0_y', axis=1, inplace=True)\n",
    "# merged_df.drop('Unnamed: 0_x', axis=1, inplace=True)\n",
    "\n",
    "# Remove rows with NaN values in 'Nation' column\n",
    "merged_df.dropna(subset=['Nation'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
